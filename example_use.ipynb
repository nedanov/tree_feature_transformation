{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FYI: The classification problem below is very easy to solve, but due to the limited number of features it is useful to showcase how one can use a Tree Feature Generator.  A more difficult problem would be nicer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skin dataset - 3 features and 1 target\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00229/Skin_NonSkin.txt'\n",
    "skin_data_raw = pd.read_csv(url,sep='\\t',names=['x1','x2','x3','target'])\n",
    "skin_data_raw['target']=skin_data_raw['target'].map({1:0,2:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74</td>\n",
       "      <td>85</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73</td>\n",
       "      <td>84</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>83</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>81</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>81</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2   x3  target\n",
       "0  74  85  123       0\n",
       "1  73  84  122       0\n",
       "2  72  83  121       0\n",
       "3  70  81  119       0\n",
       "4  70  81  119       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skin_data_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skin_data_raw['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = skin_data_raw.values[:,:3]\n",
    "y = skin_data_raw.values[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#X_test,y_test used for final model evaluation\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, accuracy_score, precision_score, recall_score, f1_score, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function which summarizes results of a classifier\n",
    "#input is true y labels and the predicted labels\n",
    "def summarize_performance(y_true,y_pred,y_pred_proba):\n",
    "    acc_score = accuracy_score(y_true,y_pred)\n",
    "    prec_score = precision_score(y_true,y_pred)\n",
    "    rec_score = recall_score(y_true,y_pred)\n",
    "    f1 = f1_score(y_true,y_pred)\n",
    "    auc = roc_auc_score(y_true,y_pred)\n",
    "\n",
    "    print('accuracy: %0.6f'%(acc_score))\n",
    "    print('precision: %0.6f'%(prec_score))\n",
    "    print('recall: %0.6f'%(rec_score))\n",
    "    print('f1: %0.6f'%(f1))\n",
    "    print('auc: %0.6f'%(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function which computes true positives and false positives arrays and an AUC score for a particular model\n",
    "#inputs are the true y labels and array of predicted values generated by the model\n",
    "def generate_tp_fp_auc(y_true,y_pred_proba):\n",
    "    y_pred_proba = y_pred_proba[:,1]\n",
    "    #computing false and true positive rates\n",
    "    fpr, tpr, _ = roc_curve(y_true,y_pred_proba)\n",
    "    #computing the area under the curve\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    #roc_auc = roc_auc_score(y_true,y_pred_proba)\n",
    "    return fpr, tpr, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limiting the performance of the RF by setting max depth of 5 in order for the ROC results in the end to be legible\n",
    "#otherwise the models perform evently (the problem is just really easy to solve)\n",
    "#max_depth pf 5 results in shallower trees => lower variance across trees\n",
    "rfv = RandomForestClassifier(n_estimators=10,max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val score for the Random Forest model (using F1)\n",
    "f1_scores = cross_val_score(rfv, X_train, y_train,cv=10,scoring='f1')\n",
    "print('Mean 10CV F1 Score: %0.5f' %(f1_scores.mean()))\n",
    "print('Std 10CV F1 Score: %0.5f' %(f1_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the RF on the train portion of the data\n",
    "rfv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating a model prediction using the train/test set\n",
    "y_pred_rfv_train = rfv.predict(X_train)\n",
    "y_pred_rfv_train_proba = rfv.predict_proba(X_train)\n",
    "y_pred_rfv_test = rfv.predict(X_test)\n",
    "y_pred_rfv_test_proba = rfv.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data performance\n",
    "summarize_performance(y_train,y_pred_rfv_train,y_pred_rfv_train_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data performance\n",
    "summarize_performance(y_test,y_pred_rfv_test,y_pred_rfv_test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating true and false positives for the RF for an ROC visualization\n",
    "fpr_rfv, tpr_rfv, auc_rfv = generate_tp_fp_auc(y_test,y_pred_rfv_test_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Vanilla (untunned) Gradient Boosted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limiting the performance of the GBT by setting n_estimators=10 in order for the ROC results in the end \n",
    "#to be legible otherwise the models perform evently (the problem is just really easy to solve)\n",
    "#the trees by default in boosting are shallower, so limiting the number of trees results in weaker \n",
    "#ensemble performance (compared to a RF)\n",
    "grdbv = GradientBoostingClassifier(n_estimators = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val score for the Gradient Boosting Model (using F1)\n",
    "f1_scores = cross_val_score(grdbv, X_train, y_train,cv=10,scoring='f1')\n",
    "print('Mean 10CV F1 Score: %0.5f' %(f1_scores.mean()))\n",
    "print('Std 10CV F1 Score: %0.5f' %(f1_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the GB model on the train portion of the data\n",
    "grdbv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating a model prediction using the train/test set\n",
    "y_pred_grdbv_train = grdbv.predict(X_train)\n",
    "y_pred_grdbv_train_proba = grdbv.predict_proba(X_train)\n",
    "y_pred_grdbv_test = grdbv.predict(X_test)\n",
    "y_pred_grdbv_test_proba = grdbv.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data performance\n",
    "summarize_performance(y_train,y_pred_grdbv_train,y_pred_grdbv_train_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data performance\n",
    "summarize_performance(y_test,y_pred_grdbv_test,y_pred_grdbv_test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating true and false positives for the GB model for an ROC visualization\n",
    "fpr_grdbv, tpr_grdbv, auc_grdbv = generate_tp_fp_auc(y_test,y_pred_grdbv_test_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a vanilla Linear Model using the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression by itself\n",
    "lm = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val score for the LM Model (using F1)\n",
    "f1_scores = cross_val_score(lm, X_train, y_train,cv=10,scoring='f1')\n",
    "print('Mean 10CV F1 Score: %0.5f' %(f1_scores.mean()))\n",
    "print('Std 10CV F1 Score: %0.5f' %(f1_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the linear model to all of the X_train data\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating a model prediction using the train/test set\n",
    "y_pred_lm_train = lm.predict(X_train)\n",
    "y_pred_lm_train_proba = lm.predict_proba(X_train)\n",
    "y_pred_lm_test = lm.predict(X_test)\n",
    "y_pred_lm_test_proba = lm.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data performance\n",
    "summarize_performance(y_train,y_pred_lm_train,y_pred_lm_train_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data performance\n",
    "summarize_performance(y_test,y_pred_lm_test,y_pred_lm_test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating true and false positives for the LM model for an ROC visualization\n",
    "fpr_lm, tpr_lm, auc_lm = generate_tp_fp_auc(y_test,y_pred_lm_test_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a vanilla version of the Tree Feature Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_feature_transformation import TreeTransformClf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tftrc = TreeTransformClf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val score for the tree feature transformer model (using F1)\n",
    "f1_scores = cross_val_score(tftrc, X_train, y_train,cv=10,scoring='f1')\n",
    "print('Mean 10CV F1 Score: %0.5f' %(f1_scores.mean()))\n",
    "print('Std 10CV F1 Score: %0.5f' %(f1_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the feature transformer model on the train portion of the data\n",
    "tftrc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating a model prediction using the train/test set\n",
    "y_pred_tftrc_train = tftrc.predict(X_train)\n",
    "y_pred_tftrc_train_proba = tftrc.predict_proba(X_train)\n",
    "y_pred_tftrc_test = tftrc.predict(X_test)\n",
    "y_pred_tftrc_test_proba = tftrc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data performance\n",
    "summarize_performance(y_train,y_pred_tftrc_train,y_pred_tftrc_train_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data performance\n",
    "summarize_performance(y_test,y_pred_tftrc_test,y_pred_tftrc_test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating true and false positives for the LM model for an ROC visualization\n",
    "fpr_tftrc, tpr_tftrc, auc_tftrc = generate_tp_fp_auc(y_test,y_pred_tftrc_test_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing AUC across the various models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr_rfv, tpr_rfv, label='RF')\n",
    "plt.plot(fpr_tftrc, tpr_tftrc, label='RF + LR')\n",
    "plt.plot(fpr_grdbv, tpr_grdbv, label='GBT')\n",
    "plt.plot(fpr_lm, tpr_lm,label='LR')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.xlim(-0.01, 0.2)\n",
    "plt.ylim(0.85, 1.01)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr_rfv, tpr_rfv, label='RF')\n",
    "plt.plot(fpr_tftrc, tpr_tftrc, label='RF + LR')\n",
    "plt.plot(fpr_grdbv, tpr_grdbv, label='GBT')\n",
    "plt.plot(fpr_lm, tpr_lm,label='LR')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves (Zoomed-in)')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of how the Tree Feature Generator Model can be tuned through Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TreeTransformClf(tree_clf=RandomForestClassifier(),\n",
    "                       meta_clf=LogisticRegression(),\n",
    "                       blend_split=0.5,\n",
    "                       random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"tree_clf__max_depth\":[3,5,None],\n",
    "              \"tree_clf__max_features\":[1,2,3],\n",
    "              \"tree_clf__random_state\" : [0],\n",
    "              \"tree_clf__n_jobs\" : [-1],\n",
    "              \"meta_clf__penalty\" : ['l1','l2'],\n",
    "              \"meta_clf__C\" : [10,1,0.1,0.001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline and GridSearch integration example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca',PCA()),\n",
    "                 ('clf',TreeTransformClf(tree_clf=RandomForestClassifier(),meta_clf=LogisticRegression()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"pca__n_components\" : [2,3],\n",
    "              \"clf__tree_clf__max_depth\":[3,5,None],\n",
    "              \"clf__tree_clf__max_features\":[1,2],\n",
    "              \"clf__tree_clf__random_state\" : [0],\n",
    "              \"clf__tree_clf__n_jobs\" : [-1],\n",
    "              \"clf__meta_clf__penalty\" : ['l1','l2'],\n",
    "              \"clf__meta_clf__C\" : [10,1,0.1,0.001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search =  GridSearchCV(pipe, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of using tree models other than RF for feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomTreesEmbedding, GradientBoostingClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TreeTransformClf(tree_clf=GradientBoostingClassifier(),\n",
    "                       meta_clf=LogisticRegression(),\n",
    "                       blend_split=0.5,\n",
    "                       random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean CV F1 score with GB\n",
    "cross_val_score(clf, X_train, y_train, cv=10,scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TreeTransformClf(tree_clf=ExtraTreesClassifier(),\n",
    "                       meta_clf=LogisticRegression(),\n",
    "                       blend_split=0.5,\n",
    "                       random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean CV F1 score with Extra Trees\n",
    "cross_val_score(clf, X_train, y_train, cv=10,scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TreeTransformClf(tree_clf=RandomTreesEmbedding(),\n",
    "                       meta_clf=LogisticRegression(),\n",
    "                       blend_split=0.5,\n",
    "                       random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean CV F1 score with Tree Embedding\n",
    "cross_val_score(clf, X_train, y_train, cv=10,scoring='f1').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
